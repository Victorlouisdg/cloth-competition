{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grasp Planning\n",
    "\n",
    "🚧 This notebook is still under construction.\n",
    "\n",
    "> ℹ️ If you want to run this notebook, you will need to install additional dependencies.\n",
    "> You can try creating the conda environment in `environment-dev.yaml`, which should include the necessary dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "current_team = \"AIR_JNU\"\n",
    "dataset_dir = Path(f\"data/dry_run_2024-05-13/{current_team}\")\n",
    "sample_id = \"2024-05-13_06-55-58-069285\"\n",
    "\n",
    "sample_dir = dataset_dir / f\"sample_{sample_id}\"\n",
    "grasps_dir = dataset_dir / f\"grasps_{sample_id}\" # TODO throughout this notebook add grasp.json files \n",
    "\n",
    "os.path.exists(sample_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cloth_tools.dataset.format import load_competition_observation\n",
    "\n",
    "observation_start_dir = sample_dir / \"observation_start\"\n",
    "\n",
    "observation = load_competition_observation(observation_start_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from cloth_tools.annotation.grasp_annotation import grasp_hanging_cloth_pose\n",
    "# import numpy as np\n",
    "\n",
    "# grasp_pose_fixed = grasp_hanging_cloth_pose(np.array([0, 0, 0.5]), np.array([1, 0, 0]), 0.0)\n",
    "# grasp_pose_fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls $grasps_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from airo_dataset_tools.data_parsers.pose import Pose\n",
    "\n",
    "\n",
    "grasp_path = grasps_dir / \"grasp_pose_2024-05-13_07-03-39-732404.json\"\n",
    "\n",
    "with open(grasp_path, \"r\") as f:\n",
    "    grasp_pose = Pose.model_validate_json(f.read()).as_homogeneous_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from cloth_tools.visualization.opencv import draw_pose\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X_W_C = observation.camera_pose_in_world\n",
    "intrinsics = observation.camera_intrinsics\n",
    "\n",
    "image_bgr = cv2.cvtColor(observation.image_left, cv2.COLOR_RGB2BGR)\n",
    "draw_pose(image_bgr, grasp_pose, intrinsics, X_W_C, 0.1)\n",
    "image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(image_rgb)\n",
    "plt.title(\"Grasp pose\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cloth_tools.drake.scenes import make_drake_scene_from_observation\n",
    "\n",
    "scene = make_drake_scene_from_observation(observation, include_cloth_obstacle=False)\n",
    "scene_with_cloth = make_drake_scene_from_observation(observation, include_cloth_obstacle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "from cloth_tools.kinematics.constants import TCP_TRANSFORM\n",
    "from cloth_tools.kinematics.inverse_kinematics import inverse_kinematics_in_world_fn\n",
    "\n",
    "X_W_LCB = observation.arm_left_pose_in_world\n",
    "X_W_RCB = observation.arm_right_pose_in_world\n",
    "\n",
    "inverse_kinematics_left_fn = partial(inverse_kinematics_in_world_fn, X_W_CB=X_W_LCB, tcp_transform=TCP_TRANSFORM)\n",
    "inverse_kinematics_right_fn = partial(inverse_kinematics_in_world_fn, X_W_CB=X_W_RCB, tcp_transform=TCP_TRANSFORM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cloth_tools.drake.scenes import make_dual_arm_collision_checker\n",
    "\n",
    "\n",
    "collision_checker_no_cloth = make_dual_arm_collision_checker(scene)\n",
    "collision_checker_with_cloth = make_dual_arm_collision_checker(scene_with_cloth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cloth_tools.kinematics.constants import JOINT_BOUNDS\n",
    "from airo_planner import DualArmOmplPlanner\n",
    "\n",
    "planner_pregrasp = DualArmOmplPlanner(\n",
    "    is_state_valid_fn=collision_checker_with_cloth.CheckConfigCollisionFree,\n",
    "    inverse_kinematics_left_fn=inverse_kinematics_left_fn,\n",
    "    inverse_kinematics_right_fn=inverse_kinematics_right_fn,\n",
    "    joint_bounds_left=JOINT_BOUNDS,\n",
    "    joint_bounds_right=JOINT_BOUNDS,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cloth_tools.planning.grasp_planning import plan_pregrasp_and_grasp_trajectory\n",
    "from airo_drake import animate_dual_joint_trajectory\n",
    "\n",
    "trajectory_pregrasp_and_grasp = plan_pregrasp_and_grasp_trajectory(\n",
    "    planner_pregrasp,\n",
    "    grasp_pose,\n",
    "    observation.arm_left_joints,\n",
    "    observation.arm_right_joints,\n",
    "    inverse_kinematics_left_fn,\n",
    "    inverse_kinematics_right_fn,\n",
    "    collision_checker_no_cloth.CheckConfigCollisionFree,\n",
    "    scene.robot_diagram.plant(),\n",
    "    with_left=False\n",
    ")\n",
    "\n",
    "animate_dual_joint_trajectory(\n",
    "    scene_with_cloth.meshcat,\n",
    "    scene_with_cloth.robot_diagram,\n",
    "    scene_with_cloth.arm_left_index,\n",
    "    scene_with_cloth.arm_right_index,\n",
    "    trajectory_pregrasp_and_grasp,\n",
    ")\n",
    "\n",
    "print(f\"You can see the trajectory animation at: {scene_with_cloth.meshcat.web_url()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cloth_tools.planning.grasp_planning import ExhaustedOptionsError\n",
    "from airo_drake.visualization import add_meshcat_triad, publish_dual_arm_joint_path, publish_ik_solutions\n",
    "\n",
    "\n",
    "def is_grasp_executable_fn(observation, grasp_pose) -> bool:\n",
    "    scene = make_drake_scene_from_observation(observation, include_cloth_obstacle=False)\n",
    "    scene_with_cloth = make_drake_scene_from_observation(observation, include_cloth_obstacle=True)\n",
    "\n",
    "    add_meshcat_triad(scene_with_cloth.meshcat, \"grasp_pose\", X_W_Triad=grasp_pose, length=0.2)\n",
    "\n",
    "    X_W_LCB = observation.arm_left_pose_in_world\n",
    "    X_W_RCB = observation.arm_right_pose_in_world\n",
    "\n",
    "    inverse_kinematics_left_fn = partial(inverse_kinematics_in_world_fn, X_W_CB=X_W_LCB, tcp_transform=TCP_TRANSFORM)\n",
    "    inverse_kinematics_right_fn = partial(inverse_kinematics_in_world_fn, X_W_CB=X_W_RCB, tcp_transform=TCP_TRANSFORM)\n",
    "\n",
    "    collision_checker_no_cloth = make_dual_arm_collision_checker(scene)\n",
    "    collision_checker_with_cloth = make_dual_arm_collision_checker(scene_with_cloth)\n",
    "\n",
    "    planner_pregrasp = DualArmOmplPlanner(\n",
    "        is_state_valid_fn=collision_checker_with_cloth.CheckConfigCollisionFree,\n",
    "        inverse_kinematics_left_fn=inverse_kinematics_left_fn,\n",
    "        inverse_kinematics_right_fn=inverse_kinematics_right_fn,\n",
    "        joint_bounds_left=JOINT_BOUNDS,\n",
    "        joint_bounds_right=JOINT_BOUNDS,\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        plan_pregrasp_and_grasp_trajectory(\n",
    "            planner_pregrasp,\n",
    "            grasp_pose,\n",
    "            observation.arm_left_joints,\n",
    "            observation.arm_right_joints,\n",
    "            inverse_kinematics_left_fn,\n",
    "            inverse_kinematics_right_fn,\n",
    "            collision_checker_no_cloth.CheckConfigCollisionFree,\n",
    "            scene.robot_diagram.plant(),\n",
    "            with_left=False,\n",
    "        )\n",
    "    except ExhaustedOptionsError:\n",
    "        return False\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "is_grasp_executable_fn(observation, grasp_pose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grasp_pose_unreachable = grasp_hanging_cloth_pose(np.array([0, 0, 1.5]), np.array([1, 0, 0]), 0.5)\n",
    "print(grasp_pose_unreachable)\n",
    "\n",
    "is_grasp_executable_fn(observation, grasp_pose_unreachable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cloth-competition-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
