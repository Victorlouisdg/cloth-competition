{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background removal\n",
    "\n",
    "In this notebook we show how you can use the depth maps to remove most of the background from the images. \n",
    "This is important because all data was recorded with the same background, but the models have to be able to generalize to different backgrounds.\n",
    "The background at the ICRA 2024 will also be different than during the data collection.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "from airo_camera_toolkit.point_clouds.conversions import point_cloud_to_open3d\n",
    "from cloth_tools.dataset.format import load_competition_observation\n",
    "\n",
    "data_dir = Path(\"data\")\n",
    "dataset_dir = data_dir / \"cloth_competition_dataset_0000\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.exists(dataset_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observation_start_dir = dataset_dir / \"sample_000000\" / \"observation_start\"\n",
    "\n",
    "observation = load_competition_observation(observation_start_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(observation.depth_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_max = 1.55\n",
    "plt.imshow(observation.depth_map < distance_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from airo_camera_toolkit.image_transforms.transforms.crop import Crop\n",
    "\n",
    "x_middle = observation.depth_map.shape[1] // 2\n",
    "width = 350\n",
    "\n",
    "x = x_middle - width // 2\n",
    "y = 240\n",
    "height = 600\n",
    "\n",
    "crop_depth = Crop(observation.depth_map.shape, x=x, y=y, w=width, h=height)\n",
    "crop_rgb_left = Crop(observation.image_left.shape, x=x, y=y, w=width, h=height)\n",
    "\n",
    "depth_cropped = crop_depth.transform_image(observation.depth_map)\n",
    "\n",
    "segmentation_mask = observation.depth_map < distance_max\n",
    "segmentation_mask_cropped = crop_depth.transform_image(segmentation_mask)\n",
    "\n",
    "crop_rgb_left = Crop(observation.image_left.shape, x=x, y=y, w=width, h=height)\n",
    "image_left_cropped = crop_rgb_left.transform_image(observation.image_left)\n",
    "\n",
    "depth_map_cropped_segmented = depth_cropped * segmentation_mask_cropped\n",
    "image_left_cropped_segmented = image_left_cropped * segmentation_mask_cropped[:, :, None]\n",
    "\n",
    "\n",
    "distance_cloth_min = np.min(depth_map_cropped_segmented[depth_map_cropped_segmented > 0.0])\n",
    "distance_cloth_max = np.max(depth_map_cropped_segmented)\n",
    "\n",
    "print(\"Shape of crop:\", depth_cropped.shape)\n",
    "print(f\"Cloth distance range: {distance_cloth_min:.2f} - {distance_cloth_max:.2f}\")\n",
    "\n",
    "plt.figure(figsize=(18, 5))\n",
    "plt.subplot(1, 5, 1)\n",
    "plt.title(\"Cropped depth map\")\n",
    "plt.imshow(depth_cropped)\n",
    "plt.subplot(1, 5, 2)\n",
    "plt.title(\"Cropped segmentation mask\")\n",
    "plt.imshow(segmentation_mask_cropped)\n",
    "plt.subplot(1, 5, 3)\n",
    "plt.title(\"Segmented cropped depth map\")\n",
    "depth_map_im = plt.imshow(depth_map_cropped_segmented)\n",
    "depth_map_im.set_clim(vmin=distance_cloth_min, vmax=distance_cloth_max) # increases contrast\n",
    "plt.subplot(1, 5, 4)\n",
    "plt.title(\"Cropped left image\")\n",
    "plt.imshow(image_left_cropped)\n",
    "plt.subplot(1, 5, 5)\n",
    "plt.title(\"Segmented cropped left image\")\n",
    "plt.imshow(image_left_cropped_segmented)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rgb_left_cropped = crop_rgb_left.transform_image(observation.image_left)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cloth_tools.annotation.grasp_annotation import GraspAnnotation\n",
    "\n",
    "\n",
    "grasp_dir = dataset_dir / \"sample_000000\" / \"grasp\"\n",
    "grasp_annotation_file = grasp_dir / \"grasp_annotation.json\"\n",
    "\n",
    "with open(grasp_annotation_file, \"r\") as f:\n",
    "    grasp_annotation = GraspAnnotation.model_validate_json(f.read())\n",
    "\n",
    "\n",
    "grasp_annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = observation.image_left\n",
    "\n",
    "clicked_point = grasp_annotation.clicked_point_frontal\n",
    "x, y = clicked_point\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.imshow(image)\n",
    "plt.scatter(x, y, c=\"lawngreen\", s=50, marker=\"x\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = image_left_cropped_segmented\n",
    "\n",
    "clicked_point_in_crop = crop_rgb_left.transform_point(grasp_annotation.clicked_point_frontal)\n",
    "x, y = clicked_point_in_crop\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.imshow(image)\n",
    "plt.scatter(x, y, c=\"lawngreen\", s=100, marker=\"x\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cloth-competition",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
