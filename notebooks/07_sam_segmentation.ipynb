{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from cloth_tools.dataset.format import load_competition_observation\n",
    "\n",
    "data_dir = Path(\"data\")\n",
    "dataset_dir = data_dir / \"cloth_competition_references_0001\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.exists(dataset_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observation_dirs = [dataset_dir / ref_dir for ref_dir in sorted(os.listdir(dataset_dir))]\n",
    "len(observation_dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0\n",
    "observation = load_competition_observation(observation_dirs[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(observation.image_left)\n",
    "plt.title(\"Left image\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cloth_tools.dataset.format import CompetitionObservation\n",
    "from airo_typing import Vector3DType\n",
    "from airo_camera_toolkit.pinhole_operations.projection import project_points_to_image_plane\n",
    "from airo_dataset_tools.data_parsers.camera_intrinsics import CameraIntrinsics\n",
    "from airo_spatial_algebra import transform_points\n",
    "\n",
    "# TODO change types\n",
    "def get_bounding_box_between_grippers(\n",
    "    arm_left_tcp_position: Vector3DType,\n",
    "    arm_right_tcp_position: Vector3DType,\n",
    "    intrinsics: np.ndarray,\n",
    "    extrinsics: np.ndarray,\n",
    "    y_padding: float = 0.1,\n",
    ") -> tuple[float, float, float, float]:\n",
    "\n",
    "    x_left, y_left, z_left = arm_left_tcp_position.squeeze()\n",
    "    x_right, y_right, z_right = arm_right_tcp_position.squeeze()\n",
    "\n",
    "    # Create the 3D rectangle for the bounding box\n",
    "    y_padding = 0.1\n",
    "    c1 = np.array([x_left, y_left + y_padding, z_left])\n",
    "    c2 = np.array([x_right, y_right - y_padding, z_right])\n",
    "    c3 = np.array([x_left, y_left + y_padding, 0.05])\n",
    "    c4 = np.array([x_right, y_right - y_padding, 0.05])\n",
    "\n",
    "    # Generate all corners\n",
    "    corners_3d = np.array([c1, c2, c3, c4])\n",
    "\n",
    "    X_C_W = np.linalg.inv(extrinsics)\n",
    "    projected_corners = project_points_to_image_plane(transform_points(X_C_W, corners_3d), intrinsics).squeeze()\n",
    "\n",
    "    # Get the 2D bounding box\n",
    "    u_min = min(u for u, _ in projected_corners)\n",
    "    v_min = min(v for _, v in projected_corners)\n",
    "    u_max = max(u for u, _ in projected_corners)\n",
    "    v_max = max(v for _, v in projected_corners)\n",
    "\n",
    "    return u_min, v_min, u_max, v_max\n",
    "\n",
    "\n",
    "def get_heuristic_cloth_bounding_box(observation: CompetitionObservation) -> tuple[float, float, float, float]:\n",
    "    \"\"\"Calculates an approximate 2D bounding box for the cloth region held by the robot arms.\n",
    "    This function assume the case where the cloth is held both robots arms and stretched in front of the camera.\n",
    "\n",
    "    Args:\n",
    "        sample_dir: The path to the sample directory containing the necessary data files.\n",
    "    Returns:\n",
    "        A tuple of (u_min, v_min, u_max, v_max) representing the coordinates of the\n",
    "        estimated bounding box within the image.\n",
    "    \"\"\"\n",
    "    intrinsics = observation.camera_intrinsics\n",
    "    extrinsics = observation.camera_pose_in_world\n",
    "    arm_left_tcp_position = observation.arm_left_tcp_pose_in_world[:3, 3]\n",
    "    arm_right_tcp_position = observation.arm_right_tcp_pose_in_world[:3, 3]\n",
    "    return get_bounding_box_between_grippers(arm_left_tcp_position, arm_right_tcp_position, intrinsics, extrinsics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_min, v_min, u_max, v_max = get_heuristic_cloth_bounding_box(observation)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(observation.image_left)\n",
    "plt.title(\"Left image\")\n",
    "plt.gca().add_patch(plt.Rectangle((u_min, v_min), u_max - u_min, v_max - v_min, edgecolor=\"r\", facecolor=\"none\"))\n",
    "plt.show()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sam_weights_dir = \"/home/victor/cloth-competition/evaluation-service/weights\"\n",
    "\n",
    "!ls $sam_weights_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from segment_anything import SamPredictor, sam_model_registry\n",
    "\n",
    "weights_name = \"sam_vit_h_4b8939.pth\"\n",
    "device =\"cuda\"\n",
    "\n",
    "sam_weights = os.path.join(sam_weights_dir, weights_name)\n",
    "sam = sam_model_registry[\"vit_h\"](checkpoint=sam_weights)\n",
    "sam.to(device=device)\n",
    "\n",
    "predictor = SamPredictor(sam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.set_image(observation.image_left)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_label = []\n",
    "input_point = []\n",
    "input_box = np.array([u_min, v_min, u_max, v_max])\n",
    "\n",
    "masks, _, _ = predictor.predict(\n",
    "    point_coords=np.array(input_point) if len(input_point) > 0 else None,\n",
    "    point_labels=np.array(input_label) if len(input_label) > 0 else None,\n",
    "    box=input_box[None, :],\n",
    "    multimask_output=False,\n",
    ")\n",
    "\n",
    "mask = masks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(mask)\n",
    "plt.gca().add_patch(plt.Rectangle((u_min, v_min), u_max - u_min, v_max - v_min, edgecolor=\"r\", facecolor=\"none\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cloth-competition-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
